# åŸºäºmmPencilæ•°æ®é›†çš„æ™ºèƒ½ç‰©è”ç½‘å®éªŒè¯¾ç¨‹
> ä»£ç åœ°å€ï¼ˆgithubï¼‰ï¼šhttps://github.com/1YifanGuo/NWPU_AIoT_Laboratory

> æ•°æ®é›†åœ°å€ï¼ˆkaggleï¼‰ï¼šhttps://www.kaggle.com/datasets/mmpencil/mmpencil-dataset/data
***
## ç›®å½•
- [ä¸‰ç»´éš”ç©ºæ‰‹å†™å•è¯æ¯«ç±³æ³¢é›·è¾¾æ•°æ®é›†](#1)
- [åŸºäºpythonçš„æ¯«ç±³æ³¢é›·è¾¾ä¿¡å·å¤„ç†](#2)
- [åŸºäºæ·±åº¦å­¦ä¹ çš„å­—æ¯çº§éš”ç©ºæ‰‹å†™å•è¯è¯†åˆ«](#3)
  - [æ–¹æ¡ˆä¸€ï¼šä¿¡å· â†’ é¢‘è°± â†’ å•è¯åˆ†ç±»](#3.1)
  - [æ–¹æ¡ˆäºŒï¼šä¿¡å· â†’ è½¨è¿¹å›¾åƒ â†’ å•è¯åˆ†ç±» â†’ è¯­è¨€æ¨¡å‹çº é”™](#3.2)
  - [æ–¹æ¡ˆä¸‰ï¼šä¿¡å· â†’ è½¨è¿¹å›¾åƒ â†’ è§†è§‰è¯­è¨€æ¨¡å‹å•è¯è¯†åˆ«ï¼ˆUbiCompâ€˜25ï¼‰](#3.3)

***
## 1. âœ mmPencil-datasetï¼šä¸‰ç»´éš”ç©ºæ‰‹å†™å•è¯æ¯«ç±³æ³¢é›·è¾¾æ•°æ®é›† <a id="1"></a>
### â­ï¸ æ•°æ®é›†é‡‡é›†èƒŒæ™¯
![](images/background.png)

### ğŸ“¦ æ•°æ®é›†æ¦‚è¿°

è¯¥æ•°æ®é›†åŒ…å«ä½¿ç”¨å¾·å·ä»ªå™¨IWR6843ISKé›·è¾¾é‡‡é›†çš„**ä¸‰ç»´éš”ç©ºæ‰‹å†™å•è¯æ•°æ®**ï¼Œé€‚ç”¨äºæ‰‹åŠ¿è¯†åˆ«ã€æ‰‹å†™è¯†åˆ«ã€é›·è¾¾ä¿¡å·å¤„ç†å’Œ3Dè½¨è¿¹åˆ†æç­‰ä»»åŠ¡ã€‚

æ•°æ®é›†åŒ…å«7,744ç»„æ•°æ®ï¼Œæ•´ä½“åˆ†ä¸ºä¸‰ä¸ªéƒ¨åˆ†ï¼Œåˆ†åˆ«é’ˆå¯¹ä¸åŒçš„ç ”ç©¶éœ€æ±‚ï¼š**è¯ç±»å¤šæ ·æ€§**ã€**ç”¨æˆ·å¤šæ ·æ€§**å’Œ**åœºæ™¯ä¸°å¯Œæ€§**ã€‚

![](images/dataset.png)

### ğŸ”§ ç¡¬ä»¶é…ç½®
- é›·è¾¾: TI IWR6843ISK
- æ•°æ®é‡‡é›†æ¿: DCA1000EVM
- é¢‘ç‡èŒƒå›´: 60-64 GHz
- å¤©çº¿é…ç½®: 3ä¸ªå‘å°„å¤©çº¿ï¼ˆä¸€ä¸ªä½äºä¸åŒé«˜åº¦ï¼‰+ 4ä¸ªæ¥æ”¶å¤©çº¿
- è§†åœºè§’: æ°´å¹³120Â°ï¼Œå‚ç›´60Â°
- é¢‘ç‡æ–œç‡: 66.011 MHz/Î¼s
- é‡‡æ ·ç‡: 2000 ksps
- è°ƒé¢‘é…ç½®: æ¯å¸§1ä¸ªè°ƒé¢‘ï¼Œæ¯è°ƒé¢‘108ä¸ªADCé‡‡æ ·

### ğŸ“ é‡‡é›†æ¨¡å¼
- é›·è¾¾æ”¾ç½®: å›ºå®šï¼Œæœä¸Š
- ç”¨æˆ·è¦æ±‚:
    - è‡ªç”±æ‰‹å†™ï¼Œä¸é™åˆ¶ä¸ªäººä¹¦å†™é£æ ¼
    - ä¸é™åˆ¶ç¬”ç”»é¡ºåºæˆ–æ–¹å‘
    - æ¯ä¸ªå­—æ¯å¤§çº¦ä¹¦å†™2-3ç§’

![](images/data_collection.png)
- å‚ä¸è€…: 12äººï¼ˆä¹¦å†™é£æ ¼å·®å¼‚å¦‚ä¸‹å›¾ï¼‰

![](images/12_user.png)
- å•è¯: 200ç§è‹±æ–‡å•è¯ï¼ˆç”±2-9ä¸ªå­—æ¯ç»„æˆï¼Œå¦‚ä¸‹å›¾ï¼‰

![](images/200word.png)

### ğŸ“‚ æ•°æ®é›†ç»„æˆ

**ğŸ“ 200-Word 4-User æ•°æ®é›†**
- é‡ç‚¹: å¹¿æ³›çš„è¯æ±‡è¦†ç›–
- ç”¨æˆ·: 4äºº
- æ ·æœ¬:
    - ç”¨æˆ·1 & 2: æ¯ä¸ªå•è¯10ä¸ªæ ·æœ¬ Ã— 200ä¸ªå•è¯
    - ç”¨æˆ·3 & 4: æ¯ä¸ªå•è¯2ä¸ªæ ·æœ¬ Ã— 200ä¸ªå•è¯
    - æ€»æ ·æœ¬æ•°: 4,800

**ğŸ“ 50-Word 12-User æ•°æ®é›†**
- é‡ç‚¹: ç”¨æˆ·ä¹¦å†™é£æ ¼å¤šæ ·æ€§
- ç”¨æˆ·: 12äºº
- å†…å®¹:
    - ä¸ç¬¬ä¸€éƒ¨åˆ†é‡å çš„50ä¸ªå•è¯
    - åŒ…æ‹¬æ•°å­—ï¼ˆ0-9ï¼‰å’Œç¬¦å·ï¼ˆâ†’, +ï¼‰
- æ ·æœ¬:
    - ç”¨æˆ·1 & 2: æ¯ä¸ªå•è¯10ä¸ªæ ·æœ¬ Ã— 50ä¸ªå•è¯
    - ç”¨æˆ·3 & 4: æ¯ä¸ªå•è¯2ä¸ªæ ·æœ¬ Ã— 50ä¸ªå•è¯
    - ç”¨æˆ·5 - 12: æ¯ä¸ªå•è¯4ä¸ªæ ·æœ¬ Ã— 50ä¸ªå•è¯
    - æ€»æ ·æœ¬æ•°: 3,184ï¼ˆå…¶ä¸­1,984ä¸ªæ˜¯å”¯ä¸€çš„ï¼‰

**ğŸ“ 22-Scenario 1-User æ•°æ®é›†**
- é‡ç‚¹: å¯¹å„ç§ä¹¦å†™æ¡ä»¶çš„é²æ£’æ€§
- åœºæ™¯: 22ä¸ªï¼ˆä¸åŒçš„è·ç¦»ã€è§’åº¦ã€é€Ÿåº¦ã€ç¯å¢ƒç­‰ï¼‰
- ç”¨æˆ·: 1äºº
- å•è¯: æ¯ä¸ªåœºæ™¯8ä¸ªå•è¯ï¼Œæ¯ä¸ªå•è¯5ä¸ªæ ·æœ¬
- æ€»æ ·æœ¬æ•°: 880

***

## 2. åŸºäºpythonçš„æ¯«ç±³æ³¢é›·è¾¾ä¿¡å·å¤„ç†ï¼ˆéš”ç©ºæ‰‹å†™å•è¯æ¢å¤ï¼‰<a id="2"></a>

### 2.1 å¯¼å…¥åº“å’Œå®šä¹‰å‡½æ•°

```python
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from pykalman import KalmanFilter
from sklearn.decomposition import PCA
```
**è§£é‡Š**ï¼šè¿™äº›åº“åˆ†åˆ«æ˜¯ç”¨äºæ•°å€¼è®¡ç®—ã€ç»˜å›¾ã€è¿›åº¦æ¡æ˜¾ç¤ºã€å¡å°”æ›¼æ»¤æ³¢å’Œä¸»æˆåˆ†åˆ†æã€‚

### 2.2 èŒƒå›´FFTï¼ˆRange FFTï¼‰

```python
def range_fft(data: np.ndarray, N: int) -> np.ndarray:
    """
    æ‰§è¡Œå¸¦æœ‰é›¶å¡«å……å’Œæ±‰æ˜çª—çš„èŒƒå›´FFTã€‚

    å‚æ•°:
        data (np.ndarray): è¾“å…¥å¤æ•°æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_sample, n_channel)ã€‚
        N (int): é›¶å¡«å……çš„æ’å€¼å› å­ã€‚

    è¿”å›:
        np.ndarray: FFTåçš„èŒƒå›´è½®å»“ï¼Œå½¢çŠ¶ä¸º (n_sample * N, n_channel)ã€‚
    """
    # éªŒè¯è¾“å…¥
    if not isinstance(data, np.ndarray) or not np.iscomplexobj(data):
        raise ValueError("Input data must be a complex-valued NumPy array.")
    if not isinstance(N, int) or N <= 0:
        raise ValueError("Interpolation factor N must be a positive integer.")

    # æå–è¾“å…¥æ•°æ®çš„ç»´åº¦
    n_sample, n_channel = data.shape

    # å¯¹æ•°æ®è¿›è¡Œé›¶å¡«å……
    interpolated_data = np.zeros((n_sample * N, n_channel), dtype='complex')
    interpolated_data[0:n_sample, :] = data

    # åº”ç”¨æ±‰æ˜çª—
    window = np.hanning(n_sample * N)

    # å¯¹æ¯ä¸ªé€šé“æ‰§è¡ŒFFT
    range_profile = np.zeros((n_sample * N, n_channel), dtype='complex')
    for m in range(n_channel):
        range_profile[:, m] = np.fft.fft(interpolated_data[:, m] * window, n_sample * N)

    return range_profile
```
**è§£é‡Š**ï¼šè¿™ä¸ªå‡½æ•°å®ç°äº†èŒƒå›´FFTï¼ŒåŒ…æ‹¬é›¶å¡«å……å’Œæ±‰æ˜çª—çš„åº”ç”¨ã€‚å®ƒè¿”å›æ¯ä¸ªé€šé“çš„é¢‘ç‡åŸŸè¡¨ç¤ºã€‚
**é¢‘è°±ç»†åŒ–æ•ˆæœ**ï¼š
![](images/FFT.png)
### 2.3 æ–¹ä½è§’FFTï¼ˆAzimuth FFTï¼‰

```python
def azimuth_fft(range_profile: np.ndarray) -> np.ndarray:
    """
    ä½¿ç”¨é€‰å®šçš„é€šé“å’Œ120ç‚¹FFTæ‰§è¡Œæ–¹ä½è§’FFTã€‚

    å‚æ•°:
        range_profile (np.ndarray): è¾“å…¥å¤æ•°æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_sample, n_channel)ã€‚

    è¿”å›:
        np.ndarray: FFTåçš„æ–¹ä½è§’è½®å»“ï¼Œå½¢çŠ¶ä¸º (n_sample, 120)ã€‚
    """
    # éªŒè¯è¾“å…¥
    if not isinstance(range_profile, np.ndarray) or not np.iscomplexobj(range_profile):
        raise ValueError("Input range_profile must be a complex-valued NumPy array.")

    n_sample, n_channel = range_profile.shape

    # å®šä¹‰ç”¨äºæ–¹ä½è§’FFTçš„é€šé“
    selected_channels = [0, 1, 2, 3, 8, 9, 10, 11]
    if max(selected_channels) >= n_channel:
        raise ValueError("Selected channels exceed the available range in range_profile.")

    # åˆå§‹åŒ–æ–¹ä½è§’è½®å»“
    azimuth_profile = np.zeros((n_sample, 120), dtype='complex')

    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„æ–¹ä½è§’FFT
    for m in range(n_sample):
        # æå–å½“å‰æ ·æœ¬çš„é€‰å®šé€šé“
        temp = range_profile[m, selected_channels]
        # æ‰§è¡ŒFFTå¹¶åº”ç”¨FFTç§»ä½
        azimuth_profile[m, :] = np.fft.fftshift(np.fft.fft(temp, 120))

    return azimuth_profile
```
**è§£é‡Š**ï¼šè¿™ä¸ªå‡½æ•°ä½¿ç”¨é€‰å®šçš„é€šé“å¯¹èŒƒå›´è½®å»“è¿›è¡Œæ–¹ä½è§’FFTï¼Œå¹¶è¿”å›æ–¹ä½è§’è½®å»“ã€‚

### 2.4 ä»°è§’FFTï¼ˆElevation FFTï¼‰

```python
def elevation_fft(range_profile: np.ndarray) -> np.ndarray:
    """
    ä½¿ç”¨é€‰å®šçš„é€šé“å’Œ60ç‚¹FFTæ‰§è¡Œä»°è§’FFTã€‚

    å‚æ•°:
        range_profile (np.ndarray): è¾“å…¥å¤æ•°æ•°æ®ï¼Œå½¢çŠ¶ä¸º (n_sample, n_channel)ã€‚

    è¿”å›:
        np.ndarray: FFTåçš„ä»°è§’è½®å»“ï¼Œå½¢çŠ¶ä¸º (n_sample, 60)ã€‚
    """
    # éªŒè¯è¾“å…¥
    if not isinstance(range_profile, np.ndarray) or not np.iscomplexobj(range_profile):
        raise ValueError("Input range_profile must be a complex-valued NumPy array.")

    n_sample, n_channel = range_profile.shape

    # å®šä¹‰ç”¨äºä»°è§’FFTçš„é€šé“
    selected_channels = [9, 7]
    if max(selected_channels) >= n_channel:
        raise ValueError("Selected channels exceed the available range in range_profile.")

    # åˆå§‹åŒ–ä»°è§’è½®å»“
    elevation_profile = np.zeros((n_sample, 60), dtype='complex')

    # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„ä»°è§’FFT
    for m in range(n_sample):
        # æå–å½“å‰æ ·æœ¬çš„é€‰å®šé€šé“
        temp = range_profile[m, selected_channels]
        # æ‰§è¡ŒFFTå¹¶åº”ç”¨FFTç§»ä½
        elevation_profile[m, :] = np.fft.fftshift(np.fft.fft(temp, 60))

    return elevation_profile
```
**è§£é‡Š**ï¼šè¿™ä¸ªå‡½æ•°ä½¿ç”¨é€‰å®šçš„é€šé“å¯¹èŒƒå›´è½®å»“è¿›è¡Œä»°è§’FFTï¼Œå¹¶è¿”å›ä»°è§’è½®å»“ã€‚

### 2.5 å¯»æ‰¾ç›®æ ‡ç‚¹ï¼ˆFind Target Pointï¼‰

```python
def find_target_point(map_data: np.ndarray, threshold_ratio: float) -> np.ndarray:
    """
    é€šè¿‡é˜ˆå€¼å¤„ç†å’Œèšç±»è¯†åˆ«åœ°å›¾ä¸­çš„ç›®æ ‡ç‚¹ã€‚

    å‚æ•°:
        map_data (np.ndarray): è¡¨ç¤ºåœ°å›¾æ•°æ®çš„äºŒç»´æ•°ç»„ã€‚
        threshold_ratio (float): ç›¸å¯¹äºåœ°å›¾æœ€å¤§å€¼çš„é˜ˆå€¼æ¯”ç‡ã€‚

    è¿”å›:
        np.ndarray: é›†ç¾¤ä¸­å¿ƒåæ ‡ä½œä¸ºä¸€ç»´æ•°ç»„ [x, y]ã€‚
    """
    # éªŒè¯è¾“å…¥
    if not isinstance(map_data, np.ndarray) or map_data.ndim != 2:
        raise ValueError("map_data must be a 2D NumPy array.")
    if not (0 < threshold_ratio <= 1):
        raise ValueError("threshold_ratio must be a float in the range (0, 1].")

    # è®¡ç®—é˜ˆå€¼
    threshold = threshold_ratio * np.max(map_data)

    # æŸ¥æ‰¾æ»¡è¶³é˜ˆå€¼çš„ç‚¹çš„ç´¢å¼•
    indices = np.where(map_data >= threshold)
    if len(indices[0]) == 0:
        raise ValueError("No points found above the specified threshold.")

    # å°†ç´¢å¼•è½¬æ¢ä¸ºæ•°æ®ç‚¹æ•°ç»„
    data_points = np.array(indices).T

    # è®¡ç®—é›†ç¾¤ä¸­å¿ƒï¼ˆç‚¹çš„å‡å€¼ï¼‰
    cluster_center = np.mean(data_points, axis=0)

    return cluster_center
```
**è§£é‡Š**ï¼šè¯¥å‡½æ•°é€šè¿‡é˜ˆå€¼å¤„ç†å’Œèšç±»æ–¹æ³•æ‰¾åˆ°åœ°å›¾ä¸­çš„ç›®æ ‡ç‚¹ï¼Œå¹¶è¿”å›å…¶åæ ‡ã€‚
**æ•ˆæœ**ï¼š
![](images/RA_RE.png)

### 2.6 å¤„ç†å¸§æ•°æ®ï¼ˆProcess Frameï¼‰

```python
def process_frame(transposed_data: np.ndarray,
                  sample_rate: float,
                  c: float,
                  slope: float,
                  n_sample: int,
                  N: int,
                  noise: np.ndarray,
                  target_frames: int) -> np.ndarray:
    """
    å¤„ç†é›·è¾¾å¸§ä»¥è®¡ç®—ç›®æ ‡åœ¨è·ç¦»ã€æ–¹ä½è§’å’Œä»°è§’ä¸Šçš„æ»¤æ³¢è½¨è¿¹ã€‚

    å‚æ•°:
        transposed_data (np.ndarray): è½¬ç½®çš„è¾“å…¥é›·è¾¾æ•°æ®ï¼Œå½¢çŠ¶ä¸º (target_frames, n_sample, n_channel)ã€‚
        sample_rate (float): é›·è¾¾çš„é‡‡æ ·ç‡ã€‚
        c (float): å…‰é€Ÿï¼ˆå•ä½ï¼šm/sï¼‰ã€‚
        slope (float): é›·è¾¾è°ƒé¢‘æ–œç‡ï¼ˆå•ä½ï¼šHz/sï¼‰ã€‚
        n_sample (int): æ¯å¸§çš„é‡‡æ ·æ•°ã€‚
        N (int): æ’å€¼å› å­ã€‚
        noise (np.ndarray): å™ªå£°çŸ©é˜µï¼Œä¸å•å¸§transposed_dataçš„å½¢çŠ¶ç›¸åŒã€‚
        target_frames (int): æ€»å…±è¦å¤„ç†çš„å¸§æ•°ã€‚

    è¿”å›:
        np.ndarray: å½¢çŠ¶ä¸º (filtered_frames, 3) çš„æ»¤æ³¢ç›®æ ‡ä½ç½®æ•°æ®ï¼Œåˆ—åˆ†åˆ«ä¸º [è·ç¦», æ–¹ä½è§’, ä»°è§’]ã€‚
    """
    # è®¡ç®—è·ç¦»åˆ†è¾¨ç‡
    range_resolution = sample_rate * c / (2 * slope * n_sample * N)

    # åˆå§‹åŒ–å­˜å‚¨å¤„ç†æ•°æ®çš„ç©ºé—´
    ra_map = np.zeros((target_frames, 30 * N, 120), dtype=np.float32)
    re_map = np.zeros((target_frames, 30 * N, 60), dtype=np.float32)
    location_rae = np.zeros((target_frames, 3), dtype=np.float32)

    # å¤„ç†æ¯ä¸€å¸§
    for i in tqdm(range(target_frames), desc="Processing frames"):
        # è·ç¦»-æ–¹ä½è§’å’Œè·ç¦»-ä»°è§’å¤„ç†
        current_data = transposed_data[i, :, :] - noise
        range_fft_result = range_fft(current_data, N)[:30 * N, :]

        ra_map[i, :, :] = abs(azimuth_fft(range_fft_result))
        re_map[i, :, :] = abs(elevation_fft(range_fft_result))

        # æ‰¾åˆ°RAå’ŒREåœ°å›¾çš„é›†ç¾¤ä¸­å¿ƒ
        cluster_center_ra = find_target_point(ra_map[i, :, :], 0.75)
        cluster_center_re = find_target_point(re_map[i, :, :], 0.75)

        # è®¡ç®—ç›®æ ‡çš„ä½ç½®åœ¨è·ç¦»ã€æ–¹ä½è§’å’Œä»°è§’ä¸Š
        location_rae[i, 0] = cluster_center_ra[0] * range_resolution  # è·ç¦»ï¼ˆå•ä½ï¼šç±³ï¼‰
        location_rae[i, 1] = cluster_center_ra[1] - 60  # æ–¹ä½è§’
        location_rae[i, 2] = cluster_center_re[1] - 30  # ä»°è§’

    # è¿‡æ»¤è½¨è¿¹æ•°æ®ä¸­çš„å¼‚å¸¸å€¼
    mean_values = np.mean(location_rae, axis=0)
    std_values = np.std(location_rae, axis=0)
    threshold = 3  # æ ‡å‡†å·®è¿‡æ»¤çš„é˜ˆå€¼

    filtered_data = location_rae[
        (np.abs(location_rae[:, 0] - mean_values[0]) <= threshold * std_values[0]) &
        (np.abs(location_rae[:, 1] - mean_values[1]) <= threshold * std_values[1]) &
        (np.abs(location_rae[:, 2] - mean_values[2]) <= threshold * std_values[2])
        ]

    return filtered_data
```
**è§£é‡Š**ï¼šæ­¤å‡½æ•°å¤„ç†é›·è¾¾å¸§æ•°æ®ï¼Œè®¡ç®—ç›®æ ‡åœ¨è·ç¦»ã€æ–¹ä½è§’å’Œä»°è§’ä¸Šçš„æ»¤æ³¢è½¨è¿¹ï¼Œå¹¶è¿”å›ç»“æœã€‚
**æ•ˆæœ**ï¼š
![](images/point.png)

### 2.7 å¹³æ»‘å’Œé‡å»ºè½¨è¿¹ï¼ˆSmooth and Reconstruct Trajectoryï¼‰

```python
def smooth_and_reconstruct_trajectory(location: np.ndarray,
                                      use_kalman: bool = True,
                                      kalman_observation_covariance: float = 1.0) -> np.ndarray:
    """
    ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å¹³æ»‘å’Œé‡å»º3Dè½¨è¿¹ã€‚

    å‚æ•°:
        location (np.ndarray): å½¢çŠ¶ä¸º (n_frames, 3) çš„è¾“å…¥è½¨è¿¹ï¼Œåˆ—åˆ†åˆ«ä¸º [x, y, z]ã€‚
        use_kalman (bool): æ˜¯å¦ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢è¿›è¡Œå¹³æ»‘ã€‚
        kalman_observation_covariance (float): å¡å°”æ›¼æ»¤æ³¢å™¨è§‚æµ‹åæ–¹å·®å€¼ã€‚

    è¿”å›:
        np.ndarray: å½¢çŠ¶ä¸º (n_frames, 3) çš„å¹³æ»‘è½¨è¿¹ã€‚
    """
    if not isinstance(location, np.ndarray) or location.ndim != 2 or location.shape[1] != 3:
        raise ValueError("è¾“å…¥ 'location' å¿…é¡»æ˜¯å½¢çŠ¶ä¸º (n_frames, 3) çš„NumPyæ•°ç»„ã€‚")

    if not isinstance(kalman_observation_covariance, (int, float)) or kalman_observation_covariance <= 0:
        raise ValueError("kalman_observation_covariance å¿…é¡»æ˜¯æ­£æµ®ç‚¹æ•°æˆ–æ•´æ•°ã€‚")

    # å¡å°”æ›¼æ»¤æ³¢è®¾ç½®
    kalman_transition_covariance = 1e-3  # è¾ƒå°çš„åæ–¹å·®ä»¥å®ç°å¹³æ»‘è¿‡æ¸¡
    smoothed_trajectory = location

    if use_kalman:
        # åˆå§‹åŒ–å¡å°”æ›¼æ»¤æ³¢å™¨
        kf = KalmanFilter(
            initial_state_mean=[location[0, 0], location[0, 1], location[0, 2], 0, 0, 0],
            transition_matrices=[
                [1, 0, 0, 1, 0, 0],  # ä½ç½®xä¾èµ–äºé€Ÿåº¦x
                [0, 1, 0, 0, 1, 0],  # ä½ç½®yä¾èµ–äºé€Ÿåº¦y
                [0, 0, 1, 0, 0, 1],  # ä½ç½®zä¾èµ–äºé€Ÿåº¦z
                [0, 0, 0, 1, 0, 0],  # é€Ÿåº¦xä¿æŒä¸å˜
                [0, 0, 0, 0, 1, 0],  # é€Ÿåº¦yä¿æŒä¸å˜
                [0, 0, 0, 0, 0, 1]  # é€Ÿåº¦zä¿æŒä¸å˜
            ],
            observation_matrices=[
                [1, 0, 0, 0, 0, 0],  # è§‚æµ‹x
                [0, 1, 0, 0, 0, 0],  # è§‚æµ‹y
                [0, 0, 1, 0, 0, 0]  # è§‚æµ‹z
            ],
            transition_covariance=kalman_transition_covariance * np.eye(6),
            observation_covariance=kalman_observation_covariance * np.eye(3)
        )

        # åº”ç”¨å¡å°”æ›¼å¹³æ»‘
        kalman_smoothed, _ = kf.smooth(location)
        smoothed_trajectory = kalman_smoothed[:, :3]  # æå–ä½ç½®åˆ†é‡ (x, y, z)

    return smoothed_trajectory
```
**è§£é‡Š**ï¼šè¯¥å‡½æ•°ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å™¨å¹³æ»‘å’Œé‡å»ºè½¨è¿¹ï¼Œä»¥å‡å°‘å™ªå£°å½±å“ã€‚
**æ•ˆæœ**ï¼š
![](images/trajectory.png)

### 2.8 ç»˜åˆ¶æ¸å˜çº¿ï¼ˆPlot Gradient Lineï¼‰

```python
def plot_gradient_line(ax, x, y, cmap='plasma', linewidth=2):
    """
    åœ¨ç»™å®šçš„Matplotlibè½´ä¸Šç»˜åˆ¶å¸¦æœ‰æ¸å˜é¢œè‰²æ•ˆæœçš„çº¿æ¡ã€‚

    å‚æ•°:
        ax (matplotlib.axes.Axes): è¦ç»˜åˆ¶çš„Matplotlibè½´ã€‚
        x (array-like): çº¿æ¡çš„Xåæ ‡ã€‚
        y (array-like): çº¿æ¡çš„Yåæ ‡ã€‚
        cmap (str): Matplotlibé…è‰²æ–¹æ¡ˆçš„åç§°ã€‚é»˜è®¤ä¸º 'plasma'ã€‚
        linewidth (float): çº¿æ¡å®½åº¦ã€‚é»˜è®¤ä¸º 2ã€‚
    """
    # ç¡®ä¿è¾“å…¥æœ‰æ•ˆä¸”é•¿åº¦ç›¸åŒ
    if len(x) != len(y):
        raise ValueError("x and y must have the same length.")
    if len(x) < 2:
        raise ValueError("x and y must contain at least two points to plot a line.")

    # ç”Ÿæˆæ¸å˜é¢œè‰²
    colormap = plt.colormaps[cmap]
    colors = colormap(np.linspace(0, 1, len(x) - 1))

    # ç»˜åˆ¶å¸¦æœ‰æ¸å˜é¢œè‰²çš„çº¿æ®µ
    for i in range(len(x) - 1):
        ax.plot(x[i:i+2], y[i:i+2], color=colors[i], linewidth=linewidth)
```
**è§£é‡Š**ï¼šè¿™ä¸ªè¾…åŠ©å‡½æ•°ç”¨äºç»˜åˆ¶å¸¦æœ‰æ¸å˜é¢œè‰²æ•ˆæœçš„çº¿æ¡ï¼Œç”¨äºå¯è§†åŒ–è½¨è¿¹ã€‚

### 2.9 å¯è§†åŒ–2D PCAè½¨è¿¹ï¼ˆVisualize Trajectory 2D PCAï¼‰

```python
def visualize_trajectory_2d_pca(location_ra: np.ndarray) -> None:
    """
    é€šè¿‡PCAæŠ•å½±å°†3Dè½¨è¿¹ï¼ˆè·ç¦»ï¼Œæ–¹ä½è§’ï¼Œä»°è§’ï¼‰å¯è§†åŒ–ä¸º2Dã€‚

    å‚æ•°:
        location_ra (np.ndarray): å½¢çŠ¶ä¸º (n_frames, 3) çš„è¾“å…¥è½¨è¿¹ï¼Œçƒåæ ‡ç³»ä¸­çš„ (r, æ–¹ä½è§’, ä»°è§’)ã€‚

    è¿”å›:
        None: æ˜¾ç¤º2Dè½¨è¿¹å›¾ã€‚
    """
    # éªŒè¯è¾“å…¥
    if not isinstance(location_ra, np.ndarray) or location_ra.ndim != 2 or location_ra.shape[1] != 3:
        raise ValueError("Input 'location_ra' must be a NumPy array of shape (n_frames, 3).")

    # å¹³æ»‘å’Œé‡å»ºè½¨è¿¹
    smoothed_ra = smooth_and_reconstruct_trajectory(location_ra)

    # å°†çƒåæ ‡ç³» (r, æ–¹ä½è§’, ä»°è§’) è½¬æ¢ä¸ºç¬›å¡å°”åæ ‡ç³» (x, y, z)
    x_ra = smoothed_ra[:, 0] * np.sin(np.radians(smoothed_ra[:, 1])) * np.cos(np.radians(smoothed_ra[:, 2]))
    y_ra = smoothed_ra[:, 0] * np.cos(np.radians(smoothed_ra[:, 1])) * np.cos(np.radians(smoothed_ra[:, 2]))
    z_ra = smoothed_ra[:, 0] * np.sin(np.radians(smoothed_ra[:, 2]))

    # å †å ç¬›å¡å°”åæ ‡
    cartesian_trajectory = np.vstack((x_ra, y_ra, z_ra)).T

    # ä½¿ç”¨PCAå°†3Dè½¨è¿¹é™ç»´åˆ°2D
    pca = PCA(n_components=2)
    location_2d = pca.fit_transform(cartesian_trajectory)

    # ç¡®å®šæ–¹å‘å‘é‡ï¼ˆèµ·å§‹ç‚¹åˆ°ç»“æŸç‚¹ï¼‰åœ¨2Dä¸­
    start_point = location_2d[0]
    end_point = location_2d[-1]
    direction_vector = end_point - start_point

    # æ ¹æ®ä¸»è¦ä¹¦å†™æ–¹å‘è°ƒæ•´æ–¹å‘
    if direction_vector[0] < 0:  # å¦‚æœä¸»è¦æ–¹å‘ä¸ºè´Ÿï¼Œåˆ™ç¿»è½¬Xè½´
        location_2d[:, 0] = -location_2d[:, 0]
    if direction_vector[1] > 0:  # å¦‚æœæ¬¡è¦æ–¹å‘ä¸ºæ­£ï¼Œåˆ™ç¿»è½¬Yè½´
        location_2d[:, 1] = -location_2d[:, 1]

    # ç»˜åˆ¶2Dè½¨è¿¹
    plt.figure(figsize=(8, 6))
    plot_gradient_line(plt.gca(), location_2d[:, 0], location_2d[:, 1], cmap="plasma", linewidth=6)
    plt.grid(True)

    # é…ç½®è½´æ ‡ç­¾å’Œå­—ä½“
    plt.xlabel("Primary Writing Direction", fontname='Times New Roman', fontsize=20)
    plt.ylabel("Secondary Writing Direction", fontname='Times New Roman', fontsize=20)

    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()
```
**è§£é‡Š**ï¼šè¯¥å‡½æ•°é€šè¿‡PCAå°†3Dè½¨è¿¹æŠ•å½±åˆ°2Dï¼Œå¹¶ä½¿ç”¨æ¸å˜é¢œè‰²ç»˜åˆ¶è½¨è¿¹ã€‚
**æ•ˆæœ**ï¼š
![](images/hello_world.png)
### 2.10 ä¸»ç¨‹åºï¼ˆMain Programï¼‰

```python
if __name__ == '__main__':
    # å®šä¹‰å…³é”®å‚æ•°
    n_sample = 108  # æ¯å¸§çš„é‡‡æ ·æ•°
    n_channel = 12  # æ¯å¸§çš„é€šé“æ•°
    slope = 66.0105e12  # é›·è¾¾æ ‡é¢‘æ–œç‡ï¼ˆå•ä½ï¼šHz/sï¼‰
    sample_rate = 2e6  # é‡‡æ ·ç‡ï¼ˆå•ä½ï¼šHzï¼‰
    N = 4  # FFTæ’å€¼å› å­
    c = 3e8  # å…‰é€Ÿï¼ˆå•ä½ï¼šm/sï¼‰

    # æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆæ³¨æ„æ›¿æ¢ä¸ºä½ çš„è·¯å¾„ï¼‰
    file_path = "/kaggle/input/mmpencil-dataset/mmPencil_dataset/User-01/200-Word/about/w04.npy"

    # åŠ è½½æ•°æ®
    try:
        data_cube = np.load(file_path)
    except FileNotFoundError:
        print(f"Error: File not found at {file_path}. Please check the path.")
        exit(1)
    except Exception as e:
        print(f"Error: An unexpected error occurred while loading the file: {e}")
        exit(1)

    # éªŒè¯æ•°æ®ç»´åº¦
    target_frames = data_cube.shape[0]
    if data_cube.ndim != 3 or data_cube.shape[1:] != (n_sample, n_channel):
        print("Error: Data cube dimensions do not match the expected shape (frames, samples, channels).")
        exit(1)

    # é€šè¿‡å¸§å¹³å‡è®¡ç®—é™æ€å™ªå£°
    noise = data_cube.mean(axis=0)

    # å¤„ç†å¸§æ•°æ®å¹¶è·å¾—ç›®æ ‡è½¨è¿¹
    location_ra = process_frame(data_cube, sample_rate, c, slope, n_sample, N, noise, target_frames)

    # å¯è§†åŒ–2D PCAè½¨è¿¹
    visualize_trajectory_2d_pca(location_ra)
```
**è§£é‡Š**ï¼šä¸»ç¨‹åºéƒ¨åˆ†å®šä¹‰äº†å…³é”®å‚æ•°ã€åŠ è½½æ•°æ®ã€è®¡ç®—å™ªå£°ã€å¤„ç†å¸§æ•°æ®ä»¥è·å–ç›®æ ‡è½¨è¿¹ï¼Œå¹¶æœ€ç»ˆå¯è§†åŒ–2D PCAè½¨è¿¹ã€‚

***

## 3. åŸºäºæ·±åº¦å­¦ä¹ çš„å­—æ¯çº§éš”ç©ºæ‰‹å†™å•è¯è¯†åˆ« <a id="3"></a>

### ğŸ’¡ 3.1 æ–¹æ¡ˆä¸€ï¼šä¿¡å· â†’ é¢‘è°± â†’ å•è¯åˆ†ç±» <a id="3.1"></a>

#### 3.1.1 æ•´ä½“æ€è·¯
##### æ­¥éª¤1ï¼šä¿¡å·é¢„å¤„ç†
- åŠ è½½åŸå§‹`.npy`æ–‡ä»¶
- è®¡ç®—å™ªå£°åŸºçº¿ï¼ˆæ‰€æœ‰å¸§çš„å¹³å‡å€¼ï¼‰
- ä»æ¯å¸§ä¸­å‡å»å™ªå£°

##### æ­¥éª¤2ï¼šé¢‘è°±è½¬æ¢
- **Range FFT**ï¼šä½¿ç”¨Hannçª—å’Œé›¶å¡«å……ï¼Œæå–180ä¸ªè·ç¦»bin
- **Azimuth FFT**ï¼šé€‰æ‹©ç‰¹å®šå¤©çº¿ï¼ˆ0,1,2,3,8,9,10,11ï¼‰ï¼Œè®¡ç®—æ–¹ä½è§’
- **Elevation FFT**ï¼šé€‰æ‹©å¤©çº¿9å’Œ7ï¼Œè®¡ç®—ä¿¯ä»°è§’
- å¯¹æ¯ä¸€å¸§å–å¹…åº¦å¹³å‡ï¼Œå¾—åˆ°1Dé¢‘è°±

##### æ­¥éª¤3ï¼šç‰¹å¾å­¦ä¹ 
- ä¸‰ä¸ªç‹¬ç«‹çš„Conformerç¼–ç å™¨åˆ†åˆ«å¤„ç†ä¸‰ä¸ªé€šé“
- èåˆä¸‰è·¯ç‰¹å¾ï¼ˆconcatenate + çº¿æ€§å˜æ¢ï¼‰
- æœ€ç»ˆConformerç¼–ç å™¨æå–é«˜çº§ç‰¹å¾

##### æ­¥éª¤4ï¼šåºåˆ—è¯†åˆ«
- CTCå±‚è¾“å‡ºæ¯ä¸ªæ—¶é—´æ­¥çš„å­—ç¬¦æ¦‚ç‡
- ä½¿ç”¨è´ªå¿ƒè§£ç å¾—åˆ°æœ€ç»ˆå•è¯

#### 3.1.2 æ¨¡å‹æ¶æ„
![](images/conformer_ctc.png)

#### 3.1.3 å®éªŒç»“æœ
- åŸºç¡€çš„200ç±»å•è¯åˆ†ç±»å®éªŒï¼š**å•è¯å‡†ç¡®ç‡ï¼š96.88%ã€å­—æ¯å‡†ç¡®ç‡ï¼š99.15%** *ï¼ˆéš¾åº¦â­â­ï¼‰*
- æœªè§ç”¨æˆ·å®éªŒï¼ˆç”¨æˆ·1-2æ•°æ®è®­ç»ƒï¼Œç”¨æˆ·3-4æ•°æ®æµ‹è¯•ï¼‰ï¼š**å•è¯å‡†ç¡®ç‡ï¼š58.25%ã€å­—æ¯å‡†ç¡®ç‡: 86.05%** *ï¼ˆéš¾åº¦â­â­â­â­ï¼‰*
- æœªè§å•è¯å®éªŒï¼ˆæµ‹è¯•é›†å•è¯æœªåŒ…å«åœ¨è®­ç»ƒé›†ä¸­ï¼‰ï¼š**å•è¯å‡†ç¡®ç‡: 38.58%, å­—æ¯å‡†ç¡®ç‡: 76.26%** *ï¼ˆéš¾åº¦â­â­â­â­â­ï¼‰*

> æ–¹æ¡ˆä¸€æ•™ç¨‹åœ¨ï¼š[spectrogram-based_recognition/README.md](https://github.com/1YifanGuo/NWPU_AIoT_Laboratory/blob/main/spectrogram-based_recognition/README.md)
***



### ğŸ’¡ 3.2 æ–¹æ¡ˆäºŒï¼šä¿¡å· â†’ è½¨è¿¹å›¾åƒ â†’ å•è¯åˆ†ç±» â†’ è¯­è¨€æ¨¡å‹çº é”™ <a id="3.2"></a>
#### 3.2.1 æ•´ä½“æ€è·¯

#### æ­¥éª¤1:ä¿¡å·é¢„å¤„ç†
- åŠ è½½åŸå§‹`.npy`æ–‡ä»¶
- è®¡ç®—å™ªå£°åŸºçº¿(æ‰€æœ‰å¸§çš„å¹³å‡å€¼)
- ä»æ¯å¸§ä¸­å‡å»å™ªå£°

#### æ­¥éª¤2:3Dè½¨è¿¹æå–
- **Range FFT**:ä½¿ç”¨Hannçª—å’Œé›¶å¡«å……,æå–180ä¸ªè·ç¦»bin
- **Azimuth FFT**:é€‰æ‹©ç‰¹å®šå¤©çº¿(0,1,2,3,8,9,10,11),è®¡ç®—æ–¹ä½è§’
- **Elevation FFT**:é€‰æ‹©å¤©çº¿9å’Œ7,è®¡ç®—ä¿¯ä»°è§’
- å¯¹æ¯ä¸€å¸§å®šä½ç›®æ ‡,æå–3Dåæ ‡(è·ç¦»,æ–¹ä½,ä¿¯ä»°)

#### æ­¥éª¤3:è½¨è¿¹å¹³æ»‘ä¸é™ç»´
- ä½¿ç”¨å¡å°”æ›¼æ»¤æ³¢å¹³æ»‘è½¨è¿¹,å‡å°‘å™ªå£°
- çƒåæ ‡è½¬æ¢ä¸ºç¬›å¡å°”åæ ‡(x,y,z)
- PCAé™ç»´åˆ°2Då¹³é¢,ä¿ç•™ä¸»è¦è¿åŠ¨æ–¹å‘
- è°ƒæ•´è½¨è¿¹æ–¹å‘,ç»Ÿä¸€ä¹¦å†™æ–¹å‘

#### æ­¥éª¤4:è½¨è¿¹å›¾åƒç”Ÿæˆ
- å°†2Dè½¨è¿¹ç»˜åˆ¶ä¸ºé»‘è‰²çº¿æ¡
- è‡ªé€‚åº”è°ƒæ•´å›¾åƒè¾¹ç•Œ
- ä¿å­˜ä¸ºPNGæ ¼å¼çš„ç°åº¦å›¾åƒ

#### æ­¥éª¤5:ResNetç‰¹å¾æå–
- åŠ è½½è½¨è¿¹å›¾åƒ(è°ƒæ•´å¤§å°ä¸º128Ã—256)
- ResNetæå–å¤šå°ºåº¦ç‰¹å¾(layer3 + layer4)
- ç‰¹å¾èåˆ,ä¿ç•™ç©ºé—´ä¿¡æ¯(2è¡Œç‰¹å¾)
- è¾“å‡ºåºåˆ—ç‰¹å¾ä¾›CTCä½¿ç”¨

#### æ­¥éª¤6:CTCåºåˆ—è¯†åˆ«
- CTCå±‚è¾“å‡ºæ¯ä¸ªæ—¶é—´æ­¥çš„å­—ç¬¦æ¦‚ç‡
- ä½¿ç”¨è´ªå¿ƒè§£ç å¾—åˆ°æœ€ç»ˆå•è¯
- (å¯é€‰)ä½¿ç”¨è¯­è¨€æ¨¡å‹è¿›è¡Œæ‹¼å†™çº æ­£

#### 3.2.2 æ¨¡å‹æ¶æ„
![](images/resnet_ctc.png)

#### 3.2.3 å®éªŒç»“æœ
- åŸºç¡€çš„200ç±»å•è¯åˆ†ç±»å®éªŒï¼š**å•è¯å‡†ç¡®ç‡ï¼š90.62% â†’ 91.12%ï¼ˆè¯­è¨€æ¨¡å‹çº æ­£åï¼‰**
- æœªè§ç”¨æˆ·å®éªŒï¼ˆç”¨æˆ·1-2æ•°æ®è®­ç»ƒï¼Œç”¨æˆ·3-4æ•°æ®æµ‹è¯•ï¼‰ï¼š**å•è¯å‡†ç¡®ç‡ï¼š65.25% â†’69.00%ï¼ˆè¯­è¨€æ¨¡å‹çº æ­£åï¼‰** 
- æœªè§å•è¯å®éªŒï¼ˆæµ‹è¯•é›†å•è¯æœªåŒ…å«åœ¨è®­ç»ƒé›†ä¸­ï¼‰ï¼š**å•è¯å‡†ç¡®ç‡: 49.92% â†’ 54.50%ï¼ˆè¯­è¨€æ¨¡å‹çº æ­£åï¼‰** 

> æ–¹æ¡ˆäºŒæ•™ç¨‹åœ¨ï¼š[trajectory-based_recognition/README.md](https://github.com/1YifanGuo/NWPU_AIoT_Laboratory/blob/main/trajectory-based_recognition/README.md)
***

### ğŸ’¡ 3.3 æ–¹æ¡ˆä¸‰ï¼šä¿¡å· â†’ è½¨è¿¹å›¾åƒ â†’ è§†è§‰è¯­è¨€æ¨¡å‹å•è¯è¯†åˆ«ï¼ˆUbiCompâ€˜25ï¼‰ <a id="3.3"></a>

> é¡¹ç›®åœ°å€ï¼ˆgithubï¼‰ï¼šhttps://github.com/1YifanGuo/mmPencil

> è®ºæ–‡åœ°å€ï¼ˆACMï¼‰ï¼šhttps://dl.acm.org/doi/10.1145/3749504  ğŸ”—[å¤‡ç”¨é“¾æ¥](https://www.researchgate.net/profile/Yifan-Guo-61/publication/395263539_mmPencil_Toward_Writing-Style-Independent_In-Air_Handwriting_Recognition_via_mmWave_Radar_and_Large_Vision-Language_Model/links/68e101e9d221a404b2a561bf/mmPencil-Toward-Writing-Style-Independent-In-Air-Handwriting-Recognition-via-mmWave-Radar-and-Large-Vision-Language-Model.pdf)

***

## ğŸ“„ Copyright

æœ¬æ•™ç¨‹ç”±è¥¿åŒ—å·¥ä¸šå¤§å­¦è®¡ç®—æœºå­¦é™¢**æ™ºèƒ½æ— çº¿æ„ŸçŸ¥å°ç»„**å¼€å‘ç»´æŠ¤ã€‚

**å›¢é˜Ÿä»‹ç»:**

æ™ºèƒ½æ— çº¿æ„ŸçŸ¥å°ç»„éš¶å±è¥¿åŒ—å·¥ä¸šå¤§å­¦äººæœºç‰©èåˆæ™ºèƒ½è®¡ç®—å›¢é˜Ÿï¼Œå›¢é˜Ÿå»ºæœ‰äººæœºç‰©èåˆç¾¤æ™ºè®¡ç®—æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤ã€æ™ºèƒ½æ„ŸçŸ¥ä¸è®¡ç®—å·¥ä¿¡éƒ¨é‡ç‚¹å®éªŒå®¤ã€é™•è¥¿çœåµŒå…¥ç³»ç»ŸæŠ€æœ¯é‡ç‚¹å®éªŒå®¤ç­‰ç§‘ç ”å¹³å°ã€‚

å°ç»„è´Ÿè´£äºº[ç‹æŸ±æ•™æˆ](https://jszy.nwpu.edu.cn/wangzhu.html)å…¼ä»»é™•è¥¿çœåµŒå…¥ç³»ç»ŸæŠ€æœ¯é‡ç‚¹å®éªŒå®¤å‰¯ä¸»ä»»å’Œäººæœºç‰©èåˆç¾¤æ™ºè®¡ç®—æ•™è‚²éƒ¨é‡ç‚¹å®éªŒå®¤å­¦æœ¯ç§˜ä¹¦ã€‚

---
